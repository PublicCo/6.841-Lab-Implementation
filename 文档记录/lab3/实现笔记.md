## Lab 3A

第一个任务是实现一个leader选举算法。我们先首先明确这个算法怎么做的。首先是状态图

![image-20240904131124416](C:\Users\leon\AppData\Roaming\Typora\typora-user-images\image-20240904131124416.png)

* 在刚开始（或者最后一个RPC发送且leader下线后），每个follower会被分配随机长度的等待实现准备选举。到了自己的指定时间后，这个follower就会发起一次选举请求：让任期号加一，向其他所有的follower发送请求投票的RPC
  * 如果candidate在选举过程中得到了leader的append entry心跳，会停止选举重新成为follower
  * 如果未过半，选举失败，candidate会等待随机时长再次选举
  * 如果过半，它就是新leader了。
  * 选举要求：candidate最后一条Log的版本比follower新，或者相同版本，但是candidate的log长度大于等于follower
* 如果系统中存在两个leader，（比如某个leader突然挂了，集群选了新leader，但是这个leader又复活了），那么当旧leader收到一个新版本的rpc后会自动关闭自己的心跳传输并变成follower，且开始纠错log

###  选举过程

对于一个 follower，当开始选举时，

1. **首先增大自己当前的 term**，
2. 然后切换到 candidate 状态，
3. 然后选举自己作为 leader，同时并发地向集群其他节点发送 RequestVote RPC，
4. 然后它将处于 candidate 状态，直到发生以下三种情况之一，下文会分别讨论：
   1. 该 follower 赢得此次选举，成为 leader；
   2. 另一个节点赢得此次选举，成为 leader；
   3. 选举超时，没有产生有效 leader。

## 实现记录

### Lab 3A

![image-20240905215513420](C:\Users\leon\AppData\Roaming\Typora\typora-user-images\image-20240905215513420.png)

下面是一些论文没提到/论文提到了我没看到的问题/实现的细节问题

* 计时器重置问题：当server收到心跳时/当server收到requestVote时。当收到rpc的时候需要考虑重置定时器。如果你在vote时候没有重置的话，可能会存在刚投完票就上岗成为candidate
  * 你可能可以参考这个[链接](https://www.cnblogs.com/way2backend/p/17294484.html)
  * 你应当在获取任何形式的rpc后重置计时器
* 在计时器超时开始选举后，你应当通过go协程来发出voterequest。否则等待call返回的时间太久容易超时
  * 当有一半以上**返回了结果**即可
* Term管理问题：Term是一个逻辑锁，管理任期上是否合法。因此会出现变化的地方在所有的RPC上（包括voterequest和heartbeat往返）
  * 只要你的term太旧，就自己变成follower。对于heartbeat线程的话，你还需要”自杀“关闭sending heartbeat
  * 在处理heartbeat返回值的时候，只有**任期过旧（仅在3ALAB中）**的时候自己贬为follower，而不是通过success状态值管理。因为success可能包括了连接不稳定等问题（这里存在可能的未定义，但是由于初始化success就是false了，没有处理连接不稳定问题倒也没关系）
* RPC问题：所有RPC都应该通过go routine发送，避免等待过久卡死主线程
  * 这就是本LAB最大的挑战，你需要大量使用DPrintf来检查算法运行到了哪一步
* 是否成功选举：注意：**你必须是candidate且获得过半选票才能成为leader**。有的时候可能你在某次RPC中发现自己版本过旧了而变成follower（即使你仍然在选举函数里运行）。这一般是选举到一半别人已经上位当leader了，而因为自己进程中断导致还在向所有server发送vote请求导致的。因此，在最后决定你是否为leader的时候，必须判断**你是不是candidate**。
  * 成为candidate的唯一条件是计时器超时，成为follower的条件是你的版本太旧了